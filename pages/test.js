import Head from 'next/head';
import Image from 'next/image';
import styles from '../styles/Home.module.css';
import { useEffect, useState, useRef, useContext } from 'react';
import { v4 as uuidv4 } from 'uuid';

import { createFFmpeg, fetchFile } from '@ffmpeg/ffmpeg';
import { cleanClip } from '../lib/clip-handlers/cleanClip';
import { extractAudioClip } from '../lib/clip-handlers/extractAudioClip';
import { optimiseAudioClip } from '../lib/clip-handlers/optimiseAudioClip';
import * as stage from '../lib/clip-handlers/stage-constants';

import { Loader } from '../components/Loader';
// ============FIREBASE=============
import {
  getFirestore,
  connectFirestoreEmulator,
  doc,
  deleteDoc,
  onSnapshot,
  query,
  where,
  getDocs,
  collection,
} from 'firebase/firestore';
//import needed to get firebase initiated
import { firestore, auth } from '../lib/firebase';
import { ffmpegContext, UserContext } from '../lib/context';
// ============FIREBASE=============
// const ffmpeg = createFFmpeg({
//   corePath: '/ffmpeg-core/ffmpeg-core.js',
// });
export default function Test() {
  const { user, username } = useContext(UserContext);
  const ffmpeg = useContext(ffmpegContext);

  console.log('user in test', user);
  console.log('ffmpeg', ffmpeg);

  const [ready, setReady] = useState(false);
  const [video, setVideo] = useState();
  const [audioUuid, setAudioUuid] = useState();
  const [audio, setAudio] = useState();
  const [cleanedClip, setCleanedClip] = useState();
  const [transcription, setTranscription] = useState();
  const ffmpegRatio = useRef(0);
  const [processStage, setProcessStage] = useState([]);
  const [timeTaken, setTimeTaken] = useState([]);
  const [processRatio, setProcessRatio] = useState(1);
  // let user = auth.currentUser;

  console.log('user', user);
  const AUDIOFILENAME = 'test.aac';
  const FINALAUDIO = 'finalAudio.aac';
  const PROCESSEDAUDIOFN = 'finalcut.mp4';

  const timeStampAtStage = (stage) => {
    const currTime = Math.round(+new Date());
    // can be combined
    setTimeTaken([...timeTaken, currTime]);
    setProcessStage([...processStage, stage]);
  };

  const load = async () => {
    if (!ffmpeg.isLoaded()) {
      console.log('ffmpeg was not loaded');
      try {
        await ffmpeg.load().then(() => setReady(true));
        await ffmpeg.setProgress((p) => {
          console.log('ratio', p);
          // setProgressRatio(p.ratio);
          ffmpegRatio.current = p.ratio;
        });
      } catch (e) {
        console.log('error loading ffmpeg', e);
        // setReady(false);
        // location.reload();
      }
    } else {
      console.log('ffmpeg loaded');
      setReady(true);
    }
  };

  useEffect(() => {
    load();
  }, []); // only called once
  console.log('ready', ready);
  useEffect(() => {
    //check auth for user
    if (user !== null && audioUuid !== null) {
      const userUid = user.uid;
      console.log('userUid', userUid);
      //listen for transcript
      const unsub = onSnapshot(
        doc(firestore, 'users', userUid, 'transcript', audioUuid),
        (doc) => {
          if (doc.data() !== undefined && 'response' in doc.data()) {
            console.log('currentdata:', JSON.parse(doc.data().response));
            setTranscription(JSON.parse(doc.data().response).result);
            timeStampAtStage(stage.ANALYSED_AUDIO);
          }
        }
      );

      // deleting transcript takes time
      const deleteStatus = deleteDoc(
        doc(firestore, 'users', userUid, 'transcript', audioUuid)
      );
    } else {
      console.log('no user logged in, please log in');
    }
  }, [audio]);
  return (
    <div className={styles.container}>
      <Head>
        <title>SuccinctCut</title>
        <meta name="description" content="Generated by create next app" />
        <link rel="icon" href="/favicon.ico" />
      </Head>

      <main className={styles.main}>
        <h1 className={styles.title}>Succinct Cut</h1>
        {user === null && <h3>Please log in</h3>}
        {ready && user !== null ? (
          <div className="App">
            {video && (
              <video
                controls
                width="250"
                src={URL.createObjectURL(video)}
              ></video>
            )}
            <input
              type="file"
              onChange={(e) => {
                setVideo(e.target.files?.item(0));
                //create new uuid for audio filename to be saved
                setAudioUuid(uuidv4());
                console.log(
                  'e.target.files?.item(0) :>> ',
                  e.target.files?.item(0)
                );
              }}
            />
            {processStage.length > 0 && (
              <>
                <h3>{processStage.at(-1)}</h3>
                <h3>Time taken: {timeTaken.at(-1) - timeTaken.at(0)} ms</h3>
                {/* <h3>TimeStamps: {timeTaken.join(' ms, ')} ms </h3> */}
                {/* {processRatio !== 1 && (
                  <h3>progress {(processRatio * 100).toFixed(0)} %</h3>
                )} */}

                {ffmpegRatio.current !== 1 && (
                  <h3>ffmpeg progress {ffmpegRatio.current}</h3>
                )}
              </>
            )}
            {video && (
              <>
                <button
                  onClick={() => {
                    extractAudioClip(
                      ffmpeg,
                      video,
                      FINALAUDIO,
                      setAudio,
                      audioUuid,
                      setProcessStage,
                      setProcessRatio,
                      timeStampAtStage
                    );
                    setProcessStage([]);
                    setTimeTaken([]);
                  }}
                >
                  Extract audio
                </button>
                <button
                  onClick={() => {
                    optimiseAudioClip(
                      ffmpeg,
                      video,
                      AUDIOFILENAME,
                      FINALAUDIO,
                      setAudio
                    );
                  }}
                >
                  Optimise audio
                </button>
              </>
            )}
            {audio && (
              <button
                onClick={() => {
                  cleanClip(
                    transcription,
                    ffmpeg,
                    video,
                    PROCESSEDAUDIOFN,
                    setCleanedClip,
                    timeStampAtStage
                  );
                }}
              >
                Clean clip
              </button>
            )}
            {audio && <video controls width="250" src={audio}></video>}
            {transcription && <p>{JSON.stringify(transcription)}</p>}
            {cleanedClip && (
              <video controls width="250" src={cleanedClip}></video>
            )}
          </div>
        ) : (
          <Loader show={true} />
          // <p>Loading...</p>
        )}
        <div className={styles.grid}></div>
      </main>

      <footer className={styles.footer}>
        <a
          href="https://vercel.com?utm_source=create-next-app&utm_medium=default-template&utm_campaign=create-next-app"
          target="_blank"
          rel="noopener noreferrer"
        >
          Powered by En & Sn
          <span className={styles.logo}>
            <Image src="/vercel.svg" alt="Vercel Logo" width={72} height={16} />
          </span>
        </a>
      </footer>
    </div>
  );
}
